{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae707abf90f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "import seaborn as sns\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "### LOADING DATASET\n",
    "data_dir = os.path.abspath('~/GTSRB/Final_Training/Images')\n",
    "os.path.exists(data_dir)\n",
    "\n",
    "### Function to resize the images using open cv\n",
    "def resize_cv(im):\n",
    "    return cv2.resize(im, (64, 64), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "### Loading datset\n",
    "list_images = []\n",
    "output = []\n",
    "for dir in os.listdir(data_dir):\n",
    "    if dir == '.DS_Store' :\n",
    "        continue\n",
    "    \n",
    "    inner_dir = os.path.join(data_dir, dir)\n",
    "    csv_file = pd.read_csv(os.path.join(inner_dir,\"GT-\" + dir + '.csv'), sep=';')\n",
    "    for row in csv_file.iterrows() :\n",
    "        img_path = os.path.join(inner_dir, row[1].Filename)\n",
    "        img = imread(img_path)\n",
    "        img = img[row[1]['Roi.X1']:row[1]['Roi.X2'],row[1]['Roi.Y1']:row[1]['Roi.Y2'],:]\n",
    "        img = resize_cv(img)\n",
    "        list_images.append(img)\n",
    "        output.append(row[1].ClassId)\n",
    "\n",
    " \n",
    "### Plotting the dataset\n",
    "fig = sns.distplot(output, kde=False, bins = 43, hist = True, hist_kws=dict(edgecolor=\"black\", linewidth=2))\n",
    "fig.set(title = \"Traffic signs frequency graph\",\n",
    "        xlabel = \"ClassId\",\n",
    "        ylabel = \"Frequency\")\n",
    "\n",
    "input_array = np.stack(list_images)\n",
    "\n",
    "train_y = keras.utils.np_utils.to_categorical(output)\n",
    "\n",
    "### Randomizing the dataset\n",
    "randomize = np.arange(len(input_array))\n",
    "np.random.shuffle(randomize)\n",
    "x = input_array[randomize]\n",
    "y = train_y[randomize]\n",
    "\n",
    "### Splitting the dataset in train, validation, test set\n",
    "split_size = int(x.shape[0]*0.6)\n",
    "train_x, val_x = x[:split_size], x[split_size:]\n",
    "train1_y, val_y = y[:split_size], y[split_size:]\n",
    "\n",
    "split_size = int(val_x.shape[0]*0.5)\n",
    "val_x, test_x = val_x[:split_size], val_x[split_size:]\n",
    "val_y, test_y = val_y[:split_size], val_y[split_size:]\n",
    "\n",
    "\n",
    "### Building the model\n",
    "hidden_num_units = 2048\n",
    "hidden_num_units1 = 1024\n",
    "hidden_num_units2 = 128\n",
    "output_num_units = 43\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "pool_size = (2, 2)\n",
    "input_shape = Input(shape=(32, 32,3))\n",
    "\n",
    "model = Sequential([\n",
    "\n",
    " Conv2D(16, (3, 3), activation='relu', input_shape=(64,64,3), padding='same'),\n",
    " BatchNormalization(),\n",
    "\n",
    " Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    " Dropout(0.2),\n",
    "    \n",
    " Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    "    \n",
    " Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    " Dropout(0.2),\n",
    "    \n",
    " Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    "    \n",
    " Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    " Dropout(0.2),\n",
    "\n",
    " Flatten(),\n",
    "\n",
    " Dense(units=hidden_num_units, activation='relu'),\n",
    " Dropout(0.3),\n",
    " Dense(units=hidden_num_units1, activation='relu'),\n",
    " Dropout(0.3),\n",
    " Dense(units=hidden_num_units2, activation='relu'),\n",
    " Dropout(0.3),\n",
    " Dense(units=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "\n",
    "### Training the model\n",
    "trained_model_conv = model.fit(train_x.reshape(-1,64,64,3), train1_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))                               \n",
    "\n",
    "### Prdicting the class\n",
    "pred = model.predict_classes(test_x)\n",
    "\n",
    "### Evaluating the model\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
